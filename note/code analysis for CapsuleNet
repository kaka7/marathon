ref:https://github.com/naturomics/CapsNet-Tensorflow

            input:        [batch_size 28 28]
            conv2D:       [9 9]/1 256 
PrimaryCaps:output:       [batch_size 20 20 256]
            conv2D:       [9 9]/2 256 
            output:       [batch_size 6 6 256]#[20-9+1]/2
            reshape:      [batch_size 6*6*32 8]#32个为一组，实际为[6，6,8,32],然后reshape，
            squash:       [batch_size 1152 8 1]#1152组向量，每个向量类似一个pixel，模为概率，方向为features                    
  DigitCaps:ui:reshape:   [batch_size 1152 1 8 1]:
            ui:tile:      [batch_size 1152 160 8 1]
            w_ij=         [1 1152 160 8 1]
            u_ji=w_ij*ui: [1 1152 160 8 1]#
            reduce_sum[3]:[batch_size 1152 160 1]#8个vector FC
            u_ji:reshape: [-1 1152 10 16 1]]

            实际要做的是每张图1152 8->1152 10 16，借助160，这里16 8 都是超参数，将160换成80也可以
            b_ij=         [batch_size 1152 10]#1152个特征最终FC成10 class

    routing:for iter in T:
           c_ij = softmax[b_ij axis=2]: [batch_size 1152 10]
           if iter == T-1:
             s_j=multiply[c_ij u_ji]:   [batch_size 1152 10 16 1]
             s_j=reduce_sum[s_j,axis=1]:[batch_size 1 10 16 1]
             v_j = squash[s_j]
           elif iter < T - 1
             [batch_size 1152 10 1 1]multiply[batch_size 1152 10 16 1]
             s_j=multiply[c_ij u_ji]:   [batch_size 1152 10 16 1]
             s_j=reduce_sum[s_j,axis=1]:[batch_size 1 10 16 1]             
             v_j = squash[s_j]#         [batch_size 1 10 16 1]

             v_j_tiled = tf.tile[v_j    [1 1152 1 1 1]]
             # [batch_size 1152 10 16 1][batch_size 1152 10 16 1]
             u_produce_v = reduce_sum[u_ji * v_j_tiled axis=3 keepdims=True]#[batch_size 1152 16 1]
           # b_ij += tf.reduce_sum[u_produce_v,axis=0,keep_dims=True]
             b_ij += u_produce_v
        return[v_j]

restructure,只输入对应的一个向量比如表示为1的16个vector，其他都不输入，改变vector中的值会导致结果图像变化，从而说明capsule的效果
routing时內积运算，反向时BP学习方向
由其他方法实现routing
关于实现问题：由于本文采用的是数乘，个人觉得不那么好理解,
可参考https://github.com/XifengGuo/CapsNet-Keras/blob/master/capsulenet.py
直接采用矩阵乘法，input:[6 6 256]->[6 6 8 32]->[1152 8]->[10,16]
output:[10,16]
todo:
conv3D实现[1152 8]->[10,16]



  